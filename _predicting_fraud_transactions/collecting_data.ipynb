{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Initial imports\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "from pathlib import Path\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow.keras.layers import Dense\r\n",
    "from tensorflow.keras.models import Sequential\r\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.svm import SVC\r\n",
    "from sklearn.metrics import classification_report\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Load in the CSV data into a DataFrame\r\n",
    "fraud_df = pd.read_csv(\r\n",
    "    Path../_predicting_fraud_transactions\\card_transaction_data.csvsvsv\r\n",
    ")\r\n",
    "# Display head and tail of the dataframe\r\n",
    "fraud_df\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      trans_date_trans_time        cc_num                            merchant  \\\n",
       "0             1/1/2019 0:00  3.890000e+13                fraud_Lind-Buckridge   \n",
       "1             1/1/2019 0:00  6.300000e+11     fraud_Heller, Gutmann and Zieme   \n",
       "2             1/1/2019 0:00  2.700000e+15          fraud_Rippin, Kub and Mann   \n",
       "3             1/1/2019 0:01  3.530000e+15  fraud_Kutch, Hermiston and Farrell   \n",
       "4             1/1/2019 0:03  3.760000e+14                 fraud_Keeling-Crist   \n",
       "...                     ...           ...                                 ...   \n",
       "59555        2/4/2019 23:25  2.350000e+15      fraud_Hauck, Dietrich and Funk   \n",
       "59556        2/4/2019 23:26  4.650000e+18    fraud_Swaniawski, Lowe and Robel   \n",
       "59557        2/4/2019 23:26  3.410000e+14                    fraud_Skiles LLC   \n",
       "59558        2/4/2019 23:26  5.410000e+15                    fraud_Kub-Heaney   \n",
       "59559        2/4/2019 23:27  4.570000e+15               fraud_Gottlieb-Hansen   \n",
       "\n",
       "             category     amt      first     last gender  \\\n",
       "0       entertainment  220.11     Edward  Sanchez      M   \n",
       "1         grocery_pos  107.23  Stephanie     Gill      F   \n",
       "2            misc_net    4.97   Jennifer    Banks      F   \n",
       "3       gas_transport   45.00     Jeremy    White      M   \n",
       "4            misc_pos   41.96      Tyler   Garcia      M   \n",
       "...               ...     ...        ...      ...    ...   \n",
       "59555       kids_pets   14.51     Justin      Gay      M   \n",
       "59556    shopping_pos    3.76      Julia     Bell      F   \n",
       "59557            home   36.74      Mario    Johns      M   \n",
       "59558  health_fitness  115.30    Jeffrey   Krause      M   \n",
       "59559   personal_care   48.27  Christine  Leblanc      F   \n",
       "\n",
       "                              street            city  ...      lat      long  \\\n",
       "0           594 White Dale Suite 530      Malad City  ...  42.1808 -112.2620   \n",
       "1       43039 Riley Greens Suite 393          Orient  ...  48.8878 -118.2105   \n",
       "2                     561 Perry Cove  Moravian Falls  ...  36.0788  -81.1781   \n",
       "3        9443 Cynthia Court Apt. 038         Boulder  ...  46.2306 -112.1138   \n",
       "4                   408 Bradley Rest        Doe Hill  ...  38.4207  -79.4629   \n",
       "...                              ...             ...  ...      ...       ...   \n",
       "59555        268 Hayes Rue Suite 811     Harborcreek  ...  42.1767  -79.9416   \n",
       "59556            576 House Crossroad   West Sayville  ...  40.7320  -73.1000   \n",
       "59557  62130 Miller Square Suite 785         Brinson  ...  30.9788  -84.7373   \n",
       "59558       4742 Alexandria Mountain     New Franken  ...  44.5592  -87.8235   \n",
       "59559      5097 Jodi Vista Suite 811         Deltona  ...  28.8989  -81.2473   \n",
       "\n",
       "       city_pop                                  job         dob  \\\n",
       "0          4154          Nature conservation officer   1/19/1962   \n",
       "1           149    Special educational needs teacher   6/21/1978   \n",
       "2          3495            Psychologist, counselling    3/9/1988   \n",
       "3          1939                      Patent attorney   1/12/1967   \n",
       "4            99       Dance movement psychotherapist   3/28/1986   \n",
       "...         ...                                  ...         ...   \n",
       "59555      2518                      Event organiser    2/2/1946   \n",
       "59556      4056                    Film/video editor   6/25/1990   \n",
       "59557      1461  Engineer, broadcasting (operations)    9/8/1935   \n",
       "59558      4306                        Art therapist  10/19/1989   \n",
       "59559     88735            Commercial horticulturist    4/9/1988   \n",
       "\n",
       "                              trans_num   unix_time  merch_lat  merch_long  \\\n",
       "0      a1a22d70485983eac12b5b88dad1cf95  1325376051  43.150704 -112.154481   \n",
       "1      1f76529f8574734946361c461b024d99  1325376044  49.159047 -118.186462   \n",
       "2      0b242abb623afc578575680df30655b9  1325376018  36.011293  -82.048315   \n",
       "3      6b849c168bdad6f867558c3793159a81  1325376076  47.034331 -112.561071   \n",
       "4      a41d7549acf90789359a9aa5346dcb46  1325376186  38.674999  -78.632459   \n",
       "...                                 ...         ...        ...         ...   \n",
       "59555  aef320c4181260a5fde1faa308c3263c  1328397947  42.785397  -79.290164   \n",
       "59556  bffa9d7c3531c23caf805895fba4d10d  1328398010  40.252215  -72.691363   \n",
       "59557  63a157e487768cece0b74abfc59d2af2  1328398013  31.480599  -85.145432   \n",
       "59558  730cf5285262a7071d0f764aa9d91cd9  1328398015  44.821099  -88.741285   \n",
       "59559  4e59c886ef33f7076a8c76f907b71068  1328398024  28.665763  -81.877916   \n",
       "\n",
       "       is_fraud  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "...         ...  \n",
       "59555         0  \n",
       "59556         0  \n",
       "59557         0  \n",
       "59558         0  \n",
       "59559         0  \n",
       "\n",
       "[59560 rows x 22 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>trans_date_trans_time</th>\n      <th>cc_num</th>\n      <th>merchant</th>\n      <th>category</th>\n      <th>amt</th>\n      <th>first</th>\n      <th>last</th>\n      <th>gender</th>\n      <th>street</th>\n      <th>city</th>\n      <th>...</th>\n      <th>lat</th>\n      <th>long</th>\n      <th>city_pop</th>\n      <th>job</th>\n      <th>dob</th>\n      <th>trans_num</th>\n      <th>unix_time</th>\n      <th>merch_lat</th>\n      <th>merch_long</th>\n      <th>is_fraud</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1/1/2019 0:00</td>\n      <td>3.890000e+13</td>\n      <td>fraud_Lind-Buckridge</td>\n      <td>entertainment</td>\n      <td>220.11</td>\n      <td>Edward</td>\n      <td>Sanchez</td>\n      <td>M</td>\n      <td>594 White Dale Suite 530</td>\n      <td>Malad City</td>\n      <td>...</td>\n      <td>42.1808</td>\n      <td>-112.2620</td>\n      <td>4154</td>\n      <td>Nature conservation officer</td>\n      <td>1/19/1962</td>\n      <td>a1a22d70485983eac12b5b88dad1cf95</td>\n      <td>1325376051</td>\n      <td>43.150704</td>\n      <td>-112.154481</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1/1/2019 0:00</td>\n      <td>6.300000e+11</td>\n      <td>fraud_Heller, Gutmann and Zieme</td>\n      <td>grocery_pos</td>\n      <td>107.23</td>\n      <td>Stephanie</td>\n      <td>Gill</td>\n      <td>F</td>\n      <td>43039 Riley Greens Suite 393</td>\n      <td>Orient</td>\n      <td>...</td>\n      <td>48.8878</td>\n      <td>-118.2105</td>\n      <td>149</td>\n      <td>Special educational needs teacher</td>\n      <td>6/21/1978</td>\n      <td>1f76529f8574734946361c461b024d99</td>\n      <td>1325376044</td>\n      <td>49.159047</td>\n      <td>-118.186462</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1/1/2019 0:00</td>\n      <td>2.700000e+15</td>\n      <td>fraud_Rippin, Kub and Mann</td>\n      <td>misc_net</td>\n      <td>4.97</td>\n      <td>Jennifer</td>\n      <td>Banks</td>\n      <td>F</td>\n      <td>561 Perry Cove</td>\n      <td>Moravian Falls</td>\n      <td>...</td>\n      <td>36.0788</td>\n      <td>-81.1781</td>\n      <td>3495</td>\n      <td>Psychologist, counselling</td>\n      <td>3/9/1988</td>\n      <td>0b242abb623afc578575680df30655b9</td>\n      <td>1325376018</td>\n      <td>36.011293</td>\n      <td>-82.048315</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1/1/2019 0:01</td>\n      <td>3.530000e+15</td>\n      <td>fraud_Kutch, Hermiston and Farrell</td>\n      <td>gas_transport</td>\n      <td>45.00</td>\n      <td>Jeremy</td>\n      <td>White</td>\n      <td>M</td>\n      <td>9443 Cynthia Court Apt. 038</td>\n      <td>Boulder</td>\n      <td>...</td>\n      <td>46.2306</td>\n      <td>-112.1138</td>\n      <td>1939</td>\n      <td>Patent attorney</td>\n      <td>1/12/1967</td>\n      <td>6b849c168bdad6f867558c3793159a81</td>\n      <td>1325376076</td>\n      <td>47.034331</td>\n      <td>-112.561071</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1/1/2019 0:03</td>\n      <td>3.760000e+14</td>\n      <td>fraud_Keeling-Crist</td>\n      <td>misc_pos</td>\n      <td>41.96</td>\n      <td>Tyler</td>\n      <td>Garcia</td>\n      <td>M</td>\n      <td>408 Bradley Rest</td>\n      <td>Doe Hill</td>\n      <td>...</td>\n      <td>38.4207</td>\n      <td>-79.4629</td>\n      <td>99</td>\n      <td>Dance movement psychotherapist</td>\n      <td>3/28/1986</td>\n      <td>a41d7549acf90789359a9aa5346dcb46</td>\n      <td>1325376186</td>\n      <td>38.674999</td>\n      <td>-78.632459</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>59555</th>\n      <td>2/4/2019 23:25</td>\n      <td>2.350000e+15</td>\n      <td>fraud_Hauck, Dietrich and Funk</td>\n      <td>kids_pets</td>\n      <td>14.51</td>\n      <td>Justin</td>\n      <td>Gay</td>\n      <td>M</td>\n      <td>268 Hayes Rue Suite 811</td>\n      <td>Harborcreek</td>\n      <td>...</td>\n      <td>42.1767</td>\n      <td>-79.9416</td>\n      <td>2518</td>\n      <td>Event organiser</td>\n      <td>2/2/1946</td>\n      <td>aef320c4181260a5fde1faa308c3263c</td>\n      <td>1328397947</td>\n      <td>42.785397</td>\n      <td>-79.290164</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>59556</th>\n      <td>2/4/2019 23:26</td>\n      <td>4.650000e+18</td>\n      <td>fraud_Swaniawski, Lowe and Robel</td>\n      <td>shopping_pos</td>\n      <td>3.76</td>\n      <td>Julia</td>\n      <td>Bell</td>\n      <td>F</td>\n      <td>576 House Crossroad</td>\n      <td>West Sayville</td>\n      <td>...</td>\n      <td>40.7320</td>\n      <td>-73.1000</td>\n      <td>4056</td>\n      <td>Film/video editor</td>\n      <td>6/25/1990</td>\n      <td>bffa9d7c3531c23caf805895fba4d10d</td>\n      <td>1328398010</td>\n      <td>40.252215</td>\n      <td>-72.691363</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>59557</th>\n      <td>2/4/2019 23:26</td>\n      <td>3.410000e+14</td>\n      <td>fraud_Skiles LLC</td>\n      <td>home</td>\n      <td>36.74</td>\n      <td>Mario</td>\n      <td>Johns</td>\n      <td>M</td>\n      <td>62130 Miller Square Suite 785</td>\n      <td>Brinson</td>\n      <td>...</td>\n      <td>30.9788</td>\n      <td>-84.7373</td>\n      <td>1461</td>\n      <td>Engineer, broadcasting (operations)</td>\n      <td>9/8/1935</td>\n      <td>63a157e487768cece0b74abfc59d2af2</td>\n      <td>1328398013</td>\n      <td>31.480599</td>\n      <td>-85.145432</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>59558</th>\n      <td>2/4/2019 23:26</td>\n      <td>5.410000e+15</td>\n      <td>fraud_Kub-Heaney</td>\n      <td>health_fitness</td>\n      <td>115.30</td>\n      <td>Jeffrey</td>\n      <td>Krause</td>\n      <td>M</td>\n      <td>4742 Alexandria Mountain</td>\n      <td>New Franken</td>\n      <td>...</td>\n      <td>44.5592</td>\n      <td>-87.8235</td>\n      <td>4306</td>\n      <td>Art therapist</td>\n      <td>10/19/1989</td>\n      <td>730cf5285262a7071d0f764aa9d91cd9</td>\n      <td>1328398015</td>\n      <td>44.821099</td>\n      <td>-88.741285</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>59559</th>\n      <td>2/4/2019 23:27</td>\n      <td>4.570000e+15</td>\n      <td>fraud_Gottlieb-Hansen</td>\n      <td>personal_care</td>\n      <td>48.27</td>\n      <td>Christine</td>\n      <td>Leblanc</td>\n      <td>F</td>\n      <td>5097 Jodi Vista Suite 811</td>\n      <td>Deltona</td>\n      <td>...</td>\n      <td>28.8989</td>\n      <td>-81.2473</td>\n      <td>88735</td>\n      <td>Commercial horticulturist</td>\n      <td>4/9/1988</td>\n      <td>4e59c886ef33f7076a8c76f907b71068</td>\n      <td>1328398024</td>\n      <td>28.665763</td>\n      <td>-81.877916</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>59560 rows × 22 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Review the data types associated with the columns\r\n",
    "fraud_df.dtypes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Drop the \"trans_date_trans_time\" column from the DataFrame\r\n",
    "fraud_df = fraud_df.drop(\r\n",
    "    columns=[\r\n",
    "        \"merchant\",\"trans_date_trans_time\",\"cc_num\",\"first\",\"last\",\"street\",\"lat\",\"long\",\"city_pop\",\"job\",\"trans_num\",\"unix_time\",\"merch_lat\",\"merch_long\"\r\n",
    "        ]\r\n",
    ").copy()\r\n",
    "\r\n",
    "# Review the DataFrame\r\n",
    "fraud_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a list of categorical values\r\n",
    "catergorical_variables = list(fraud_df.dtypes[fraud_df.dtypes ==\"object\"].index)\r\n",
    "\r\n",
    "# Encode categorical variables using OneHotEncoder\r\n",
    "catergorical_variables"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a OneHotEncoder instance\r\n",
    "enc = OneHotEncoder(sparse=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Encode the categorcal variables using OneHotEncoder\r\n",
    "encoded_data = enc.fit_transform(fraud_df[catergorical_variables])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a dataframe with the encoded variables\r\n",
    "encoded_df = pd.DataFrame(\r\n",
    "    encoded_data,\r\n",
    "    columns=enc.get_feature_names(catergorical_variables)\r\n",
    "\r\n",
    ")\r\n",
    "# Display sample data\r\n",
    "encoded_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a DataFrame with the columns containing numerical variables from the original dataset\r\n",
    "encoded_df = pd.concat([encoded_df,fraud_df.drop(columns=catergorical_variables)], axis=1)\r\n",
    "\r\n",
    "# Review the DataFrame\r\n",
    "encoded_df\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Define the target set y using the \"is_fraud\" column\r\n",
    "y = encoded_df[\"is_fraud\"]\r\n",
    "\r\n",
    "# Display a sample of y\r\n",
    "y[:10]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Define the features set X by selecting all columns but \"is_fraud\"\r\n",
    "X = encoded_df.drop(columns=[\"is_fraud\"])\r\n",
    "\r\n",
    "# Review the feature DataFrame\r\n",
    "X.head(10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Split the preprocessed data into training and testing datasets\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a StandardScaler instance\r\n",
    "scaler = StandardScaler()\r\n",
    "\r\n",
    "# Fit the StandardScaler\r\n",
    "X_scaler = scaler.fit(X_train)\r\n",
    "\r\n",
    "# Scale the data\r\n",
    "X_train_scaled = scaler.transform(X_train)\r\n",
    "X_test_scaled = scaler.transform(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Define the number of inputs to the model\r\n",
    "number_input_features = len(X_train.iloc[0])\r\n",
    "\r\n",
    "# Review the number of features\r\n",
    "number_input_features\r\n",
    "\r\n",
    "# Define the number of neurons in the output layer\r\n",
    "number_output_neurons = 1\r\n",
    "\r\n",
    "# Define the number of hidden nodes for the first hidden layer\r\n",
    "hidden_nodes_layer1 = (number_input_features + 1) // 2\r\n",
    "\r\n",
    "# Review the number of hidden nodes in the first layer\r\n",
    "hidden_nodes_layer1\r\n",
    "\r\n",
    "# Define the number of hidden nodes for the second hidden layer\r\n",
    "hidden_nodes_layer2 = (hidden_nodes_layer1 + 1) // 2\r\n",
    "\r\n",
    "# Review the number of hidden nodes in the second layer\r\n",
    "hidden_nodes_layer2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create the Sequential model instance\r\n",
    "nn = Sequential()\r\n",
    "\r\n",
    "# Add the first hidden layer\r\n",
    "nn.add(Dense(units = hidden_nodes_layer1, input_dim = number_input_features, activation = \"relu\"))\r\n",
    "\r\n",
    "# Add the second hidden layer\r\n",
    "nn.add(Dense(units = hidden_nodes_layer2, activation = \"relu\"))\r\n",
    "\r\n",
    "# Add the output layer to the model specifying the number of output neurons and activation function\r\n",
    "nn.add(Dense(units = number_output_neurons , activation=\"sigmoid\"))\r\n",
    "\r\n",
    "# Display the Sequential model summary\r\n",
    "nn.summary()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Compile the Sequential model\r\n",
    "nn.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Fit the model using 50 epochs and the training data\r\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=50)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\r\n",
    "model_loss, model_accuracy =  nn.evaluate(X_test_scaled,y_test,verbose=2)\r\n",
    "\r\n",
    "# Display the model loss and accuracy results\r\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Imported more libraries to run classifier\r\n",
    "from sklearn.svm import SVC\r\n",
    "from sklearn.metrics import classification_report\r\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\r\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create the classifier model\r\n",
    "model = SVC()\r\n",
    "\r\n",
    "# Fit the model to the data using X_train_scaled and y _train\r\n",
    "model = model.fit(X_train, y_train)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Use the trained model to predict fraudulent transactions on a customers account\r\n",
    "training_transactions_predictions = model.predict(X_train)\r\n",
    "\r\n",
    "# Evaluate the model using the classification report\r\n",
    "training_report = classification_report(\r\n",
    "    y_train,\r\n",
    "    training_transactions_predictions\r\n",
    ")\r\n",
    "\r\n",
    "print(training_report)\r\n",
    "#training_report"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Instantiate a BalancedRandomForestClassifier instance\r\n",
    "brf = BalancedRandomForestClassifier()\r\n",
    "\r\n",
    "# Fit the model to the training data\r\n",
    "brf.fit(X_train_scaled, y_train)\r\n",
    "\r\n",
    "# Predict labels for testing features\r\n",
    "y_pred = brf.predict(X_test_scaled)\r\n",
    "\r\n",
    "# Print classification report\r\n",
    "print(classification_report(y_test, y_pred))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "# Create a random forest classifier\r\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=1)\r\n",
    "\r\n",
    "# Fitting the model\r\n",
    "rf_model = rf_model.fit(X_train_scaled, y_train)\r\n",
    "\r\n",
    "# Making predictions using the testing data\r\n",
    "predictions = rf_model.predict(X_test_scaled)\r\n",
    "\r\n",
    "# Displaying results\r\n",
    "print(classification_report(y_test, predictions))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Needed for decision tree visualization\r\n",
    "%matplotlib inline\r\n",
    "import pydotplus\r\n",
    "from IPython.display import Image\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Random Forests in sklearn will automatically calculate feature importance\r\n",
    "importances = rf_model.feature_importances_\r\n",
    "\r\n",
    "# Zip the feature importances with the associated feature name\r\n",
    "important_features = zip(X.columns,rf_model.feature_importances_)\r\n",
    "\r\n",
    "important_features\r\n",
    "\r\n",
    "# Create a dataframe of the important features\r\n",
    "importances_df = pd.DataFrame(important_features)\r\n",
    "\r\n",
    "# Rename the columns\r\n",
    "importances_df = importances_df.rename(columns={0: 'Feature', 1: 'Importance'})\r\n",
    "\r\n",
    "# Set the index\r\n",
    "importances_df = importances_df.set_index('Feature')\r\n",
    "\r\n",
    "# Sort the dataframe by feature importance\r\n",
    "importances_df = importances_df.sort_values(by='Importance',ascending=False)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot the top 15 most important features\r\n",
    "importances_df[0:15].plot(\r\n",
    "    figsize= (15,8),\r\n",
    "    kind='barh', \r\n",
    "    color='lightgreen', \r\n",
    "    title= 'Feature Importance', \r\n",
    "    legend=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "importances_df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}